{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o5zUxAAuKFgf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o5zUxAAuKFgf",
    "outputId": "c872505b-d6f0-4de9-d511-b7af8961b205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 3D CNN model for frame interpolation...\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Parameters\n",
    "IMG_SIZE = (128, 128)     # (width, height)\n",
    "NUM_PAST = 2              # Number of past frames\n",
    "NUM_FUTURE = 2            # Number of future frames\n",
    "WINDOW_SIZE = NUM_PAST + 1 + NUM_FUTURE  # Total frames per window (5)\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "def extract_frames(video_path):\n",
    "    \"\"\"Extracts all frames from a given video file.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "def save_sequence(sequence, output_dir, video_name, seq_index):\n",
    "    \"\"\"Saves a sequence of frames into a dedicated subfolder.\"\"\"\n",
    "    seq_folder = os.path.join(output_dir, f\"{video_name}_seq_{seq_index}\")\n",
    "    os.makedirs(seq_folder, exist_ok=True)\n",
    "    for i, frame in enumerate(sequence):\n",
    "        frame_path = os.path.join(seq_folder, f\"frame_{i}.jpg\")\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "\n",
    "def generate_dataset(input_folder, train_folder, test_folder, train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Processes each video in the input folder.\n",
    "\n",
    "    Uses a sliding window (of WINDOW_SIZE frames) to generate sequences.\n",
    "    Each sequence is randomly assigned to train or test.\n",
    "    \"\"\"\n",
    "    os.makedirs(train_folder, exist_ok=True)\n",
    "    os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".mp4\"):\n",
    "            video_path = os.path.join(input_folder, filename)\n",
    "            video_name = os.path.splitext(filename)[0]\n",
    "            frames = extract_frames(video_path)\n",
    "            total_frames = len(frames)\n",
    "            seq_index = 0\n",
    "            for i in range(total_frames - WINDOW_SIZE + 1):\n",
    "                sequence = frames[i:i + WINDOW_SIZE]\n",
    "                # Randomly assign the sequence to training or testing set\n",
    "                if np.random.rand() < train_ratio:\n",
    "                    save_sequence(sequence, train_folder, video_name, seq_index)\n",
    "                else:\n",
    "                    save_sequence(sequence, test_folder, video_name, seq_index)\n",
    "                seq_index += 1\n",
    "\n",
    "def load_sequence(seq_path):\n",
    "    \"\"\"\n",
    "    Loads and sorts frames from a sequence folder.\n",
    "    Assumes frame filenames are like \"frame_0.jpg\", \"frame_1.jpg\", etc.\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    file_list = sorted([f for f in os.listdir(seq_path) if f.endswith(\".jpg\") and f.startswith(\"frame_\")])\n",
    "    for filename in file_list:\n",
    "        img_path = os.path.join(seq_path, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, IMG_SIZE)\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        frames.append(img)\n",
    "    return frames\n",
    "\n",
    "def process_sequence_3d(frames, num_past=NUM_PAST, num_future=NUM_FUTURE):\n",
    "    \"\"\"\n",
    "    Given a list of WINDOW_SIZE frames, forms:\n",
    "      - Input: a 4-frame sequence formed by the first num_past frames and the last num_future frames.\n",
    "      - Target: the middle frame.\n",
    "    \"\"\"\n",
    "    if len(frames) != (num_past + 1 + num_future):\n",
    "        return None, None\n",
    "    # Input frames: past (frames 0 to num_past-1) and future (frames num_past+1 to end)\n",
    "    input_frames = frames[:num_past] + frames[num_past+1:]\n",
    "    target_frame = frames[num_past]\n",
    "    return np.array(input_frames), np.array(target_frame)\n",
    "\n",
    "def dataset_from_folder_3d(folder, num_past=NUM_PAST, num_future=NUM_FUTURE):\n",
    "    \"\"\"\n",
    "    Builds a tf.data.Dataset from a folder containing sequence subfolders.\n",
    "    Each item is a tuple: (input_frames, target_frame) where:\n",
    "      - input_frames: shape (NUM_PAST+NUM_FUTURE, H, W, 3)\n",
    "      - target_frame: shape (H, W, 3)\n",
    "    \"\"\"\n",
    "    inputs_list, targets_list = [], []\n",
    "    for seq_folder in os.listdir(folder):\n",
    "        seq_path = os.path.join(folder, seq_folder)\n",
    "        if os.path.isdir(seq_path):\n",
    "            frames = load_sequence(seq_path)\n",
    "            # Slide a window over the frames\n",
    "            for i in range(len(frames) - WINDOW_SIZE + 1):\n",
    "                window = frames[i:i+WINDOW_SIZE]\n",
    "                inp, tar = process_sequence_3d(window, num_past, num_future)\n",
    "                if inp is not None and tar is not None:\n",
    "                    inputs_list.append(inp)\n",
    "                    targets_list.append(tar)\n",
    "    if not inputs_list:\n",
    "        raise ValueError(\"No valid sequences found in folder {}.\".format(folder))\n",
    "    inputs_np = np.stack(inputs_list, axis=0)  # shape: (N, NUM_PAST+NUM_FUTURE, H, W, 3)\n",
    "    targets_np = np.stack(targets_list, axis=0)  # shape: (N, H, W, 3)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((inputs_np, targets_np))\n",
    "    return dataset\n",
    "\n",
    "def build_3d_conv_model(input_shape):\n",
    "    \"\"\"\n",
    "    Builds a 3D CNN model.\n",
    "\n",
    "    Input shape: (T, H, W, 3), where T = NUM_PAST+NUM_FUTURE (e.g. 4).\n",
    "    The model aggregates temporal information and outputs a predicted frame (H, W, 3).\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=input_shape)  # e.g., (4, 128, 128, 3)\n",
    "\n",
    "    x = layers.Conv3D(64, (3,3,3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling3D(pool_size=(1,2,2))(x)  # spatial pooling only\n",
    "    x = layers.Conv3D(128, (3,3,3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling3D(pool_size=(1,2,2))(x)\n",
    "    x = layers.Conv3D(256, (3,3,3), activation='relu', padding='same')(x)\n",
    "    #x = layers.MaxPooling3D(pool_size=(1,2,2))(x) # Removed this MaxPooling layer\n",
    "\n",
    "    x = layers.Conv3DTranspose(128, (3,3,3), strides=(1,2,2), padding='same', activation='relu')(x)\n",
    "    x = layers.Conv3DTranspose(64, (3,3,3), strides=(1,2,2), padding='same', activation='relu')(x)\n",
    "\n",
    "\n",
    "    # Aggregate temporal information by averaging over the time dimension\n",
    "    x = layers.Lambda(lambda t: tf.reduce_mean(t, axis=1))(x)  # now shape: (H, W, channels)\n",
    "    output = layers.Conv2D(3, (3,3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    model = models.Model(inputs, output)\n",
    "    return model\n",
    "\n",
    "# Generate the dataset sequences from videos (if not already generated)\n",
    "input_folder = \"../input\"    # Folder containing your mp4 videos\n",
    "train_folder = \"../train\"    # Folder for training sequences\n",
    "test_folder = \"../test\"      # Folder for testing sequences\n",
    "generate_dataset(input_folder, train_folder, test_folder)\n",
    "\n",
    "# Prepare datasets using the 3D pipeline\n",
    "train_ds = dataset_from_folder_3d(train_folder)\n",
    "train_ds = train_ds.shuffle(100).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = dataset_from_folder_3d(test_folder)\n",
    "test_ds = test_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Build and compile the 3D CNN model\n",
    "# Input shape: (NUM_PAST+NUM_FUTURE, H, W, 3) => (4, 128, 128, 3)\n",
    "input_shape = (NUM_PAST + NUM_FUTURE, IMG_SIZE[1], IMG_SIZE[0], 3)\n",
    "model_3d = build_3d_conv_model(input_shape)\n",
    "model_3d.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "print(\"Training 3D CNN model for frame interpolation...\")\n",
    "history_3d = model_3d.fit(train_ds, epochs=EPOCHS, validation_data=test_ds)\n",
    "\n",
    "print(\"Evaluating 3D CNN model on test data...\")\n",
    "loss, mae = model_3d.evaluate(test_ds)\n",
    "print(\"Test Loss:\", loss, \"Test MAE:\", mae)\n",
    "\n",
    "# (Optional) Make predictions on test samples and inspect their shapes\n",
    "for inputs, targets in test_ds.take(1):\n",
    "    predictions = model_3d.predict(inputs)\n",
    "    print(\"Predictions shape:\", predictions.shape)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
