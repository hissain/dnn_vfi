# Video Frame Interpolation (VFI) - Demo Using DNN

This repository contains a machine learning demo for video frame interpolation (VFI) using three different models: UNet, RIFE, and Mamba. The goal is to predict an intermediate frame (2nd frame) given the 1st and 3rd frames as input. The project is under the MIT license.

## ğŸ“‚ Project Structure
```
.
â”œâ”€â”€ LICENSE                # MIT License
â”œâ”€â”€ README.md              # Project Documentation
â”œâ”€â”€ __pycache__/           # Compiled Python files
â”œâ”€â”€ input/                 # Sample videos
â”‚   â”œâ”€â”€ enjoy.mp4
â”‚   â”œâ”€â”€ glob.mp4
â”‚   â””â”€â”€ motion.mp4
â”œâ”€â”€ mamba/                 # Mamba-based VFI
â”‚   â”œâ”€â”€ vfi.ipynb
â”‚   â””â”€â”€ vfi_model.py
â”œâ”€â”€ requirements.txt       # Required dependencies
â”œâ”€â”€ rife/                  # RIFE-based VFI
â”‚   â””â”€â”€ RIFE.ipynb
â””â”€â”€ unet/                  # UNet-based VFI
    â”œâ”€â”€ Unet2d.ipynb
    â””â”€â”€ Unet3d.ipynb
```

## ğŸš€ Models Implemented

__UNet:__ Convolutional neural network (CNN) based architecture for frame interpolation.

__RIFE:__ Real-time Intermediate Flow Estimation model.

__Mamba:__ A sequence modeling architecture applied to frame interpolation.

## ğŸ“Œ Features

* Sample videos included for testing.

* Frame extraction and dataset preparation.

* Training notebooks for different models.

## ğŸ”§ Installation

Clone the repository and install dependencies:

```
git clone https://github.com/hissain/dnn_vfi.git
cd dnn_vfi
pip install -r requirements.txt
```

## ğŸ“Š Usage

Run the corresponding Jupyter notebooks inside the mamba/, rife/, or unet/ directories to train and evaluate the models.

jupyter notebook

## ğŸ“œ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ¤ Contributing

Feel free to submit issues or pull requests to improve the project!

## ğŸ“¬ Contact

For any inquiries, reach out to [hissain.khan@gmail.com] or create an issue in the repository.
